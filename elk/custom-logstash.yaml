logstashJavaOpts: "-Xmx256m -Xms256m"

resources:
  requests:
    cpu: "100m"
    memory: "1Gi"
  limits:
    cpu: "1000m"
    memory: "1Gi"

volumeClaimTemplate:
  accessModes: ["ReadWriteOnce"]
  storageClassName: longhorn-storage-delete
  resources:
    requests:
      storage: 512Mi

antiAffinity: "soft"

extraEnvs: 
  - name: xpack.monitoring.enabled
    value: "false"

service:
  type: ClusterIP
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: 5044
    - name: http
      port: 9600
      protocol: TCP
      targetPort: 9600

logstashPipeline:
  logstash.conf: |
    input {
      beats {
        port => "5044"
      }
    }

    filter {
      mutate {
        add_field => { "received_at" => "%{@timestamp}" }
      }

      if [service] == "frontend" {
        grok {
          match => {
            "message" => "%{YEAR:mess_detail.year}/%{MONTHNUM:mess_detail.month}/%{MONTHDAY:mess_detail.day} %{TIME:mess_detail.time} \[%{WORD:mess_detail.loglevel}\] %{NUMBER:mess_detail.pid}#%{NUMBER:mess_detail.worker}: %{GREEDYDATA:mess_detail.content}"
          }
        }
      } else if [service] == "backend" or [service] == "notification-service" {
        grok {
          match => {
            "message" => "%{TIMESTAMP_ISO8601:mess_detail.timestamp}\s+%{LOGLEVEL:mess_detail.loglevel} %{NUMBER:mess_detail.pid} --- \[%{DATA:mess_detail.service}\] \[%{DATA:mess_detail.thread}\] %{DATA:mess_detail.class}\s+:\s+%{GREEDYDATA:mess_detail.content}"
          }
        }
      } else if [service] == "rabbitmq" {
        grok {
          match => {
            "message" => "%{TIMESTAMP_ISO8601:mess_detail.timestamp} \[%{WORD:mess_detail.loglevel}\] <%{DATA:mess_detail.pid}> %{GREEDYDATA:mess_detail.content}"
          }
        }
      } else if [service] == "mysql" {
        grok {
          match => {
            "message" => "%{TIMESTAMP_ISO8601:mess_detail.timestamp} %{NUMBER:mess_detail.pid} \[%{WORD:mess_detail.loglevel}\] \[%{DATA:mess_detail.code}\] \[%{WORD:mess_detail.component}\] %{GREEDYDATA:mess_detail.content}"
          }
        }
      }

      if [mess_detail.loglevel] and [mess_detail.loglevel] =~ /(?i)error/ {
        aggregate {
          task_id => "%{service}"
          code => "map['error_count'] ||= 0; map['error_count'] += 1"
          timeout => 60
          push_map_as_event_on_timeout => true
          timeout_task_id_field => "error_service"
        }
      }
    }

    output {
      if "myopensource" in [tags] {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "myopensource_%{service}_%{+YYYY.MM.dd}"
        }
      } else if "myservice" in [tags] {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "myservice_%{service}_%{+YYYY.MM.dd}"
        }
      } else {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "default_%{+YYYY.MM.dd}"
        }
      }
    }

    output{
      if [error_service] and [error_count] > 10 {
        email {
          to => "22520527@gm.uit.edu.vn"
          from => "tienhung17092004@gmail.com"
          subject => "Logstash Alert: More than 10 ERROR logs in a minute from service %{error_service}"
          body => "There have been %{error_count} logs in the past minute from service %{error_service}."
          address => "smtp.gmail.com"
          port => 587
          username => "tienhung17092004@gmail.com"
          password => "xxxxxxx"
          authentication => "plain"
          use_tls => true
        }
      }
    }