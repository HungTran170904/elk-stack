logstashJavaOpts: "-Xmx256m -Xms256m"

resources:
  requests:
    cpu: "100m"
    memory: "1Gi"
  limits:
    cpu: "1000m"
    memory: "1Gi"

volumeClaimTemplate:
  accessModes: ["ReadWriteOnce"]
  storageClassName: longhorn-storage-delete
  resources:
    requests:
      storage: 512Mi

antiAffinity: "soft"

extraEnvs: 
  - name: xpack.monitoring.enabled
    value: "false"

service:
  type: ClusterIP
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: 5044
    - name: http
      port: 9600
      protocol: TCP
      targetPort: 9600

logstashPipeline:
  logstash.conf: |
    input {
      beats {
        port => "5044"
      }
    }

    filter {
      mutate {
        add_field => { "environment" => "production" }
      }

      if "frontend" in [tags] {
        grok {
          match => {
            "message" => "%{YEAR:message.year}/%{MONTHNUM:message.month}/%{MONTHDAY:message.day} %{TIME:message.time} \\[%{WORD:message.loglevel}\\] %{NUMBER:message.pid}#%{NUMBER:message.worker}: %{GREEDYDATA:message.content}"
          }
        }
      } else if "backend" in [tags] or "notification-service" in [tags] {
        grok {
          match => {
            "message" => "%{TIMESTAMP_ISO8601:message.timestamp}\\s+%{LOGLEVEL:message.loglevel} %{NUMBER:message.pid} --- \\[%{DATA:message.service}\\] \\[\\s+%{DATA:message.thread}\\] %{DATA:message.class}\\s+:\\s+%{GREEDYDATA:message.content}"
          }
        }
      } else if "rabbitmq" in [tags] {
        grok {
          match => {
            "message" => "%{TIMESTAMP_ISO8601:message.timestamp} \\[%{WORD:message.loglevel}\\] <%{DATA:message.pid}> %{GREEDYDATA:message.content}"
          }
        }
      } else if "mysql" in [tags] {
        grok {
          match => {
            "message" => "%{TIMESTAMP_ISO8601:message.timestamp} %{NUMBER:message.pid} \\[%{WORD:message.loglevel}\\] \\[%{DATA:message.code}\\] \\[%{WORD:message.component}\\] %{GREEDYDATA:message.content}"
          }
        }
      }

      if [message.loglevel] and [message.loglevel] =~ /(?i)error/ {
        aggregate {
          task_id => "%{tags[0]}_%{tags[1]}"
          code => "map['error_count'] ||= 0; map['error_count'] += 1"
          timeout => 60
          push_map_as_event_on_timeout => true
          timeout_task_id_field => "error_task_id"
        }
      }
    }

    output {
      if "myopensource" in [tags] {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "myopensource_%{tags[1]}_%{+YYYY.MM.dd}"
        }
      } else if "myservice" in [tags] {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "myservice_%{tags[1]}_%{+YYYY.MM.dd}"
        }
      } else {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "default_%{+YYYY.MM.dd}"
        }
      }
    }

    output{
      if [error_task_id] and [error_count] > 10 {
        email {
          to => "22520527@gm.uit.edu.vn"
          from => "tienhung17092004@gmail.com"
          subject => "Logstash Alert: More than 10 ERROR logs in a minute from service %{error_task_id}"
          body => "There have been %{error_count} logs in the past minute from service %{error_task_id}."
          address => "smtp.gmail.com"
          port => 587
          username => "tienhung17092004@gmail.com"
          password => "xxxxxxx"
          authentication => "plain"
          use_tls => true
        }
      }
    }